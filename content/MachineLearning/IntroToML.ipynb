{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fdcc8c3",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning\n",
    "\n",
    "![sklearn](../static/sklearn.png)\n",
    "\n",
    "Python is probably the most often used programming language to train and run machine learning models.\n",
    "\n",
    "For shallow machine learning models, [`sklearn`](https://scikit-learn.org) is undoubtedly the most popular library you can use. Sklearn has tutorials (check this great [*getting started*](https://scikit-learn.org/stable/getting_started.html) and this [*common pitfalls*](https://scikit-learn.org/stable/common_pitfalls.html) tutorial!), toy-datasets, extensive descriptions for all models, algorithms and many more things. Its incredible and I highly highly recommed you to use this library, if you choose to continue working with machine learning.\n",
    "\n",
    "When it comes to deep learning, python also offers a lot of options. Personally, I prefer to use [`PyTorch`](https://pytorch.org/), but there are other options. \n",
    "\n",
    "Anyway, we wont bother with deep learning in this course, so lets just skip straight to sklearn. As opposed to numpy, I prefer to directly import the classes and methods I use, instead of importing the whole module. I dont know why, but its what people just do, apparently.\n",
    "\n",
    "The first thing we will do now is fetch the breast cancer dataset from sklearn. It is a common, easy to use dataset that allows us to apply a easy binary classification. It contains features computed from digitized images of a breast mass and a binary label: malignant (0) or benign (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333f9b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import for plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7abc25d",
   "metadata": {},
   "source": [
    "We set `as_frame=True` to get both X and y as dataframe objects. Sklearn estimators typically require numpy arrays as their input, but pandas is a nice way to look at your data in a meaningful way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ae0cae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) (569,)\n"
     ]
    }
   ],
   "source": [
    "X,y = load_breast_cancer(return_X_y=True,as_frame=True)\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63112188",
   "metadata": {},
   "source": [
    "To make our data more intuitive, we can create a new variable called `diagnosis` which holds the actual labels that correspond to 0 and 1 in our y variable. We should not use this to train our model, but it makes sense to use this variable for data exploration.\n",
    "\n",
    "Before that, we should switch our 0 and 1s, so that a `malignant` tumor is the positive (1) class, and a `benignant` tumor is the negative (0) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52951116",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 1-y\n",
    "diagnosis = y.map({1:\"Malignant\",0:\"Benignant\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80060b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.07613</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.05742</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07451</td>\n",
       "      <td>...</td>\n",
       "      <td>17.06</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07389</td>\n",
       "      <td>...</td>\n",
       "      <td>15.49</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.08243</td>\n",
       "      <td>...</td>\n",
       "      <td>15.09</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "5        12.45         15.70           82.57      477.1          0.12780   \n",
       "6        18.25         19.98          119.60     1040.0          0.09463   \n",
       "7        13.71         20.83           90.20      577.9          0.11890   \n",
       "8        13.00         21.82           87.50      519.8          0.12730   \n",
       "9        12.46         24.04           83.97      475.9          0.11860   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760         0.30010              0.14710         0.2419   \n",
       "1           0.07864         0.08690              0.07017         0.1812   \n",
       "2           0.15990         0.19740              0.12790         0.2069   \n",
       "3           0.28390         0.24140              0.10520         0.2597   \n",
       "4           0.13280         0.19800              0.10430         0.1809   \n",
       "5           0.17000         0.15780              0.08089         0.2087   \n",
       "6           0.10900         0.11270              0.07400         0.1794   \n",
       "7           0.16450         0.09366              0.05985         0.2196   \n",
       "8           0.19320         0.18590              0.09353         0.2350   \n",
       "9           0.23960         0.22730              0.08543         0.2030   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "5                 0.07613  ...         15.47          23.75           103.40   \n",
       "6                 0.05742  ...         22.88          27.66           153.20   \n",
       "7                 0.07451  ...         17.06          28.14           110.60   \n",
       "8                 0.07389  ...         15.49          30.73           106.20   \n",
       "9                 0.08243  ...         15.09          40.68            97.65   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "5       741.6            0.1791             0.5249           0.5355   \n",
       "6      1606.0            0.1442             0.2576           0.3784   \n",
       "7       897.0            0.1654             0.3682           0.2678   \n",
       "8       739.3            0.1703             0.5401           0.5390   \n",
       "9       711.4            0.1853             1.0580           1.1050   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "5                0.1741          0.3985                  0.12440  \n",
       "6                0.1932          0.3063                  0.08368  \n",
       "7                0.1556          0.3196                  0.11510  \n",
       "8                0.2060          0.4378                  0.10720  \n",
       "9                0.2210          0.4366                  0.20750  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0d740df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    0\n",
       "9    0\n",
       "Name: target, dtype: int32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe8d3e5",
   "metadata": {},
   "source": [
    "Inspecting the `shape` of our feature matrix **X**, we see that we have 569 `samples` and 30 `features`.\n",
    "\n",
    "The ground truth label vector **y** is one-dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f55b1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73468710",
   "metadata": {},
   "source": [
    "### **Exercise**\n",
    "\n",
    "It makes a lot of sense to exermine the data you are dealing with. Using the seaborn library, examine the distribution (how many entries there are) of the `y` variable.\n",
    "\n",
    "**Hint**: \n",
    "\n",
    "You want to use  `sns.histplot` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818d7452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13db55bd",
   "metadata": {},
   "source": [
    "### **Exercise**\n",
    "\n",
    "Use the `sns.boxplot()` function to plot a distribution plot of a feature of your choice (e.g., a column from **X**), given the labels stored in `diagnosis`.\n",
    "\n",
    "**Hint**:\n",
    "\n",
    "Pass diagnosis to the `x` argument and the column of your choice to the `y` argument. Dont forget to be very explicit when passing the arguments to seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48131fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19978bdd",
   "metadata": {},
   "source": [
    "### **Exercise**\n",
    "\n",
    "Next thing to check would be our input data. We have 32 features ready to use in our dataframe. It makes a lot of sense to check the correlation between these features. If features are highly redundant, they may lead to a overfitting model, because there is a lot of redundancy and noise in the data. Meaning, the model learns features that may not actually be important.\n",
    "\n",
    "Typically, we want to train (adapt weights!) our model with features that are highly informative.\n",
    "\n",
    "Since our feature matrix **X** is a `pandas dataframe` we can get the correlation scores between features by calling `df.corr()`. Be sure to replace `df` with your own dataframe (X),\n",
    "\n",
    "Create a variable called `corr` and store in that variable the correlation scores. Then, use `sns.heatmap()` to plot the correlation scores. Do you notice any interesting trends? \n",
    "\n",
    "**Hint**:\n",
    "\n",
    "Try to pass the `cmap=\"coolwarm\"` argument to the `sns.heatmap` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d50652c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc2c98c6",
   "metadata": {},
   "source": [
    "You can exclude features before you actually train your model, especially if you suspect that they might influence the performance of your model. Since we only have 32 features, we can still go on with this dataset.\n",
    "\n",
    "One very very important thing you want to do before you train your model is to `normalize` your features! Non-normalized features can heavily influence the performance of your model. You dont want that to happen to you.\n",
    "\n",
    "Using the `df.describe()` method, we see that all features differ heavily in their mean, min, max and std value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "35ab1092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst radius  \\\n",
       "count     569.000000              569.000000  ...    569.000000   \n",
       "mean        0.181162                0.062798  ...     16.269190   \n",
       "std         0.027414                0.007060  ...      4.833242   \n",
       "min         0.106000                0.049960  ...      7.930000   \n",
       "25%         0.161900                0.057700  ...     13.010000   \n",
       "50%         0.179200                0.061540  ...     14.970000   \n",
       "75%         0.195700                0.066120  ...     18.790000   \n",
       "max         0.304000                0.097440  ...     36.040000   \n",
       "\n",
       "       worst texture  worst perimeter   worst area  worst smoothness  \\\n",
       "count     569.000000       569.000000   569.000000        569.000000   \n",
       "mean       25.677223       107.261213   880.583128          0.132369   \n",
       "std         6.146258        33.602542   569.356993          0.022832   \n",
       "min        12.020000        50.410000   185.200000          0.071170   \n",
       "25%        21.080000        84.110000   515.300000          0.116600   \n",
       "50%        25.410000        97.660000   686.500000          0.131300   \n",
       "75%        29.720000       125.400000  1084.000000          0.146000   \n",
       "max        49.540000       251.200000  4254.000000          0.222600   \n",
       "\n",
       "       worst compactness  worst concavity  worst concave points  \\\n",
       "count         569.000000       569.000000            569.000000   \n",
       "mean            0.254265         0.272188              0.114606   \n",
       "std             0.157336         0.208624              0.065732   \n",
       "min             0.027290         0.000000              0.000000   \n",
       "25%             0.147200         0.114500              0.064930   \n",
       "50%             0.211900         0.226700              0.099930   \n",
       "75%             0.339100         0.382900              0.161400   \n",
       "max             1.058000         1.252000              0.291000   \n",
       "\n",
       "       worst symmetry  worst fractal dimension  \n",
       "count      569.000000               569.000000  \n",
       "mean         0.290076                 0.083946  \n",
       "std          0.061867                 0.018061  \n",
       "min          0.156500                 0.055040  \n",
       "25%          0.250400                 0.071460  \n",
       "50%          0.282200                 0.080040  \n",
       "75%          0.317900                 0.092080  \n",
       "max          0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5496c9",
   "metadata": {},
   "source": [
    "Luckily, sklearn has a solution for this. We can use the `StandardScaler` function from the `preprocessing` module. `StandardScaler` allows us to scale our data to a mean of 0 and unit variance.\n",
    "\n",
    "          z = (x - u) / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b533015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7c7599",
   "metadata": {},
   "source": [
    "But now one very important thing before we proceed!\n",
    "\n",
    "Scaling your data is super important, **but** we only want to scale our `training data`! If we scale the whole dataset, we will contamine our test data, by leaking distribution information from the training set to the test set.\n",
    "\n",
    "This will render all our conclusions and our analysis meaningless.\n",
    "\n",
    "Thats why we first want to split our dataset into a `training` and `test` set.\n",
    "\n",
    "Of course, sklearn offers us a easy solution, using the `train_test_split` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4df12ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d671375",
   "metadata": {},
   "source": [
    "There are some key arguments we need to pass here. First, we need to pass our full dataset, so X and y.\n",
    "\n",
    "Then, we need to define the size of the split using the `train_size` argument. The size of this argument depends a lot on the data size you have available, choosing 70% to 80% is a good rule of thumb here. \n",
    "\n",
    "At last, we can also set the `random_state` argument to enhance reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1b580f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.8,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199f5dc8",
   "metadata": {},
   "source": [
    "### **Exercise** \n",
    "\n",
    "Inspect the shape of your training and test data to see, if your split worked as intended. You want to see less samples in your test data and more samples in your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d0525e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95e555e4",
   "metadata": {},
   "source": [
    "Now with this out of the way, we can now actually scale our data. We want to call the `Scaler.fit_transform` on our training data and `Scaler.transform` on our test data.\n",
    "\n",
    "This way, we make sure, that the test data is scaled using the training distribution, and there is no leakage beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0c3a96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = Scaler.fit_transform(X_train)\n",
    "X_test_scaled = Scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f753509f",
   "metadata": {},
   "source": [
    "### **Exercise**\n",
    "\n",
    "Using the np.mean() function, examine how the scaled and the non scaled arrays differ. \n",
    "\n",
    "**Hint**: You can use the `axis` argument, to either view the mean of the samples (rows) or the features (columns). axis = 0 will give you the mean per column (average column across all samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48860f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c16f54a0",
   "metadata": {},
   "source": [
    "Now that our features are properly scaled, we can tend to our classification model. We already discussed a logistic regression classifier in more detail, but there are of course many more estimators. One could use.\n",
    "\n",
    "For example, there are `support vector machines`, `decision trees` or the `random forest` classifier. We'll start our model training with the logistic regression and then compare different classifiers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5908de4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29110bea",
   "metadata": {},
   "source": [
    "After loading the model `class` we need to first intiate it. We can pass several arguments to the LogisticRegression class (try LogisticRegression?), but for now we keep it simple and only pass `random_state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a3a4fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe28a7c",
   "metadata": {},
   "source": [
    "With our data properly preprocessed and scaled, we are ready to train the model.  \n",
    "\n",
    "Model training in `sklearn` works by calling the `model.fit()` method.\n",
    "\n",
    "What the `fit()` function does is finding the proper model coefficients (weights). We need to pass both `X_train_scaled` and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c653f777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70a0ddb",
   "metadata": {},
   "source": [
    "Now the first thing we want to do is check the achieved training accuracy. We do that with the `model.score()` function and need to pass both the X and the y variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01ca1b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9868131868131869"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565f1499",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Calculate the test accuracy of the trained model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61595a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "762cb5bb",
   "metadata": {},
   "source": [
    "While accuracy is certainly one metric to check after fitting a classifier, there is more to come. We can visualize our results per class using a `classification report`. This classification report not only returns us the accuracy, but also the precision, recall and f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d219bb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e005f8",
   "metadata": {},
   "source": [
    "To use the classification report, we need to pass both `y_true` and `y_pred`. We already have `y_true`, but we have not explicitly calculated `y_pred` yet. You can get the predicted values using `model.predict(X)`.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Get the predicted y labels from your `test data` and name it `y_pred_test`. Apply the `classification_report` function and print the report afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fd3bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9100cb38",
   "metadata": {},
   "source": [
    "Explaination of the metrics:\n",
    "\n",
    "High **precision** means fewer false alarms (false positives). Of all the times we predicted positive, how many were actually positive?; Relates more to quality\n",
    "\n",
    "**Recall** = Of all the actual positives, how many did we correctly predict?; Relates more to quantity\n",
    "\n",
    "**F1-Score** = Harmonic mean of both metrics\n",
    "\n",
    "We can further visualize the performance of your classifier using a `confusion matrix`, which we display using seaborn. \n",
    "\n",
    "### Exercise\n",
    "\n",
    "Insert your true and predicted y values in the `confusion_matrix('y true', 'y test')` code snippet and run the cell. How did our classifier do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc684d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate the confusion matrix\n",
    "cm = confusion_matrix('y true', 'y test')\n",
    "\n",
    "# Define class names and store it in a list\n",
    "class_names = ['Benign', 'Malignant']\n",
    "\n",
    "# Plot the confusion matrix using sns.heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, \n",
    "            yticklabels=class_names)\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe97d4d",
   "metadata": {},
   "source": [
    "Now while that is pretty interesting, we can also further investigate, how the training actually influenced and changed the weights of the model.\n",
    "\n",
    "Remember, that the weights were adapted using `gradient descent`. How would you interpret these coefficients?\n",
    "\n",
    "**Hint**: The model equation for the logistic regression was \n",
    "\n",
    "          z = X(i) * w + b\n",
    "\n",
    "Try to answer the following questions:\n",
    "\n",
    "1. What does a negative and a positive coefficient mean?\n",
    "\n",
    "2. Do you have an idea, why there is a dysbalance between positive and negative coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eb464f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Feature  Coefficient\n",
      "15        compactness error     0.685972\n",
      "19  fractal dimension error     0.613405\n",
      "5          mean compactness     0.542106\n",
      "18           symmetry error     0.499980\n",
      "8             mean symmetry     0.235713\n",
      "11            texture error     0.188640\n",
      "16          concavity error     0.180815\n",
      "9    mean fractal dimension     0.076701\n",
      "25        worst compactness     0.005207\n",
      "4           mean smoothness    -0.066754\n"
     ]
    }
   ],
   "source": [
    "feature_names = X.columns  \n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': model.coef_[0]\n",
    "})\n",
    "print(coef_df.sort_values(by='Coefficient', ascending=False)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "32e387af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=coef_df,x=\"Feature\",y=\"Coefficient\")\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88f600c",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "Now sometimes you may end up working with datasets, that have limited data available. Since sufficient data is crucial for machine learning models, splitting your data into a `train`, `test` and `validation` set might really impair the predictive abilities of your model.\n",
    "\n",
    "Thats is a situation where you want to use `cross validation`. There are multiple ways to go on about `cross validation`, the most common one is implementing the `K-Fold` split.\n",
    "\n",
    "Here, the whole dataset is split into `k` different sets, the model is fit and evaluated on the remaining parts of the data. We repeat this procedure and report the average performance across all `k splits`.\n",
    "\n",
    "![crossval](../static/crossval.png)\n",
    "\n",
    "Atlast, you still want to use a hold-out test set to evaluate your model, but you still save some time.\n",
    "\n",
    "Also, cross validation can help with overfitting, because you train your model not only on an arbitraty data split, but on multiple instances. \n",
    "\n",
    "This gives us a more robust and reliable model estimation.\n",
    "\n",
    "We import the `cross_val_score` function from `sklearn.model_selection`. We actually dont need to scale our data now, because this will happen implicitly, when we pass the Scaler to a `pipeline` element.\n",
    "\n",
    "What we also want to do is use something called `Stratified K-Fold`. This is especially helpful when dealing with imbalanced data. `Stratified K-Fold` makes sure, that in each K- split are approximately an equal number of labels (target classes).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4c19902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score,StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6151770",
   "metadata": {},
   "source": [
    "After importing the modules, we initiate a Pipeline Object. We pass both a Scaler and a Classifier we want to evaluate. Then, we initiate the stratified K Fold. We define `K` with the `n_splits` argument.\n",
    "\n",
    "At last we simply call cross_val_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2af3308f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96842105, 0.96842105, 0.98941799])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),        \n",
    "    ('classifier', LogisticRegression())  \n",
    "])\n",
    "\n",
    "# Set up Stratified K-Fold \n",
    "stratified_kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# call cross validation\n",
    "cross_val_score(pipeline, X, y, cv=stratified_kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebf9d3b",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Try to fit the cross validation varying splits. Does the output change? \n",
    "\n",
    "Try to fit the cross validation function *without* the scaler in the Pipeline object. Does the behavior differ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379d8ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e2cad34",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
